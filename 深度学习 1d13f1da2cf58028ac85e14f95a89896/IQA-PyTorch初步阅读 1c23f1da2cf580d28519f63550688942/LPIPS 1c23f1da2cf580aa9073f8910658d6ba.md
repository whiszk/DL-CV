# LPIPS

<aside>
ğŸ‘“

@whiszk 

04/05/2025 

</aside>

> å‚è€ƒæ–‡çŒ®ï¼š
> 
> 
> [1801.03924](https://arxiv.org/pdf/1801.03924)
> 

---

## ä¸€ã€æŒ‡æ ‡åŸç†

**LPIPS**ï¼ˆLearned Perceptual Image Patch Similarityï¼Œå­¦ä¹ æ„ŸçŸ¥å›¾åƒå—ç›¸ä¼¼åº¦ï¼‰æ˜¯ä¸€ç§åŸºäºæ·±åº¦å­¦ä¹ çš„å›¾åƒç›¸ä¼¼åº¦åº¦é‡æ ‡å‡†ã€‚ä¸ä¼ ç»Ÿçš„åŸºäºåƒç´ çš„å›¾åƒç›¸ä¼¼åº¦æŒ‡æ ‡ï¼ˆå¦‚ PSNR å’Œ SSIMï¼‰ä¸åŒï¼ŒLPIPSå°è¯•æ¨¡æ‹Ÿäººç±»è§†è§‰æ„ŸçŸ¥ç³»ç»Ÿå¯¹å›¾åƒè´¨é‡çš„åˆ¤æ–­ï¼Œé‡ç‚¹å…³æ³¨**è§†è§‰æ„ŸçŸ¥ä¸Šçš„ç›¸ä¼¼æ€§**ï¼Œè€Œéåƒç´ çº§çš„ç›¸ä¼¼æ€§ã€‚

å¦‚ä¸‹å›¾æ‰€ç¤ºï¼šåœ¨patch0ï¼Œ1ä¸­é€‰å–ä¸referenceç›¸è¿‘çš„å›¾ç‰‡ï¼Œpsnrï¼ŒssimæŒ‡æ ‡é€‰æ‹©çš„å›¾ç‰‡å¾€å¾€ä¸äººç±»ç›´è§‰ç›¸èƒŒï¼Œè€Œæœ‰æ— ç›‘ç£ä¸‹çš„lpipséƒ½èƒ½å¾ˆå¥½è´´è¿‘äººç±»é€‰æ‹©ï¼Œå¯è§è¯¥æŒ‡æ ‡çš„å¼ºå¤§ã€‚

![image.png](LPIPS%201c23f1da2cf580aa9073f8910658d6ba/image.png)

VGGå·ç§¯ç¥ç»ç½‘ç»œåœ¨åŸå§‹ä»»åŠ¡ä¸­ä¸»è¦ç”¨äºå›¾åƒåˆ†ç±»ï¼Œå…¶æœ¬è´¨æ˜¯é€šè¿‡å±‚å±‚å·ç§¯æå–å›¾åƒçš„è¯­ä¹‰ç‰¹å¾ï¼Œå¹¶æœ€ç»ˆè¾“å‡ºå¯¹åº”ç±»åˆ«çš„é¢„æµ‹ç»“æœã€‚è€Œåœ¨LPIPSæŒ‡æ ‡ä¸­ï¼ŒVGGè¢«ç”¨ä½œä¸€ç§**æ„ŸçŸ¥ç‰¹å¾æå–å™¨**ï¼Œå…¶ä½œç”¨ä¸å†æ˜¯åˆ†ç±»ï¼Œè€Œæ˜¯æå–å¤šå±‚æ¬¡çš„è¯­ä¹‰ç‰¹å¾ç”¨äºå›¾åƒè´¨é‡è¯„ä¼°ã€‚

å…·ä½“æ¥è¯´ï¼ŒLPIPSå°†ä¸¤å¼ å¾…æ¯”è¾ƒçš„å›¾åƒåŒæ—¶è¾“å…¥åŒä¸€ä¸ªé¢„è®­ç»ƒçš„ VGG ç½‘ç»œï¼Œå¹¶ä»å¤šä¸ªå·ç§¯å—çš„è¾“å‡ºä¸­æå–ç‰¹å¾å›¾ã€‚éšåï¼ŒLPIPSå¯¹æ¯ä¸€å±‚ç‰¹å¾å›¾è¿›è¡Œ**åƒç´ çº§å·®å¼‚æ¯”è¾ƒ**ï¼ˆå¦‚L2è·ç¦»ï¼‰ï¼Œç„¶åé€šè¿‡è®­ç»ƒå¾—åˆ°çš„ä¸€ç»„çº¿æ€§åŠ æƒå±‚ï¼ˆ1Ã—1å·ç§¯ï¼‰å¯¹å„å±‚å·®å¼‚è¿›è¡ŒåŠ æƒèåˆï¼Œæœ€ç»ˆå¾—åˆ°ä¸€ä¸ªåæ˜ å›¾åƒæ„ŸçŸ¥ç›¸ä¼¼æ€§çš„åˆ†æ•°ã€‚è¯¥åˆ†æ•°è¶Šå°ï¼Œè¡¨ç¤ºä¸¤å¼ å›¾åœ¨äººç±»æ„ŸçŸ¥ä¸Šè¶Šç›¸ä¼¼ã€‚

> å…³äºVGGçš„æ¶æ„ç»†èŠ‚ï¼Œå¯è§é“¾æ¥ï¼š
> 
> 
> [VGGå·ç§¯ç¥ç»ç½‘ç»œ](../VGG%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%201cc3f1da2cf580ceb919c5452535fa3b.md)
> 

---

## äºŒã€ä»£ç æ‹†è§£

### 1.lpipsç±»

```python
è·¯å¾„ï¼š/home/whiszk/IQA-PyTorch/pyiqa/archs/lpips_arch.py

class LPIPS(nn.Module):
    def __init__(
        self,
        pretrained=True,  # æ˜¯å¦é‡‡ç”¨é¢„è®¾çš„é¢„è®­ç»ƒæ–¹å¼
        net='alex',  # åŸºç¡€ç½‘ç»œç±»å‹ï¼ˆvgg/alex/squeezeï¼‰
        version='0.1',
        lpips=True,  # æ˜¯å¦å¯ç”¨ LPIPS æ¨¡å¼ï¼›Falseæƒ…å†µä¸‹ï¼Œåªç”¨å¹³å‡L2å·®å¼‚è®¡ç®—ï¼Œä¸åŠ çº¿æ€§å±‚
        spatial=False,  # æ˜¯å¦è¿”å›ç©ºé—´æ„ŸçŸ¥ mapï¼ˆå¦‚ heatmapï¼‰ï¼Œé»˜è®¤åªè¿”å›å•ä¸ªåˆ†æ•°
        pnet_rand=False,  # ä¸»å¹²ç½‘ç»œæ˜¯å¦ä½¿ç”¨éšæœºåˆå§‹åŒ–ï¼Œå¦‚æœè®¾ä¸ºFalseï¼Œè¡¨ç¤ºä¸»å¹²ç½‘ç»œä½¿ç”¨é¢„è®­ç»ƒå‚æ•°ï¼ˆé€šå¸¸åœ¨ImageNetä¸Šè®­ç»ƒè¿‡ï¼‰
        pnet_tune=False,  # æ˜¯å¦è®­ç»ƒä¸»å¹²ç½‘ç»œçš„å‚æ•°ï¼Œå¦‚æœè®¾ä¸ºFalseï¼Œä¸»å¹²ç½‘ç»œæ˜¯å†»ç»“çš„ï¼ˆä¸å‚ä¸è®­ç»ƒï¼‰
        use_dropout=True,
        pretrained_model_path=None,
        eval_mode=True,  # æ§åˆ¶æ¨¡å‹æ˜¯å¦å¤„äºè¯„ä¼°æ¨¡å¼ï¼Œä¸ºtrueæ—¶ï¼ŒDropoutå…³é—­ï¼Œ
        semantic_weight_layer=-1,  # æ§åˆ¶è¯­ä¹‰åŠ æƒç­–ç•¥ï¼Œå¢å¼ºå¯¹å…³é”®åŒºåŸŸçš„å…³æ³¨ï¼Œå‚æ•°å€¼è¡¨ç¤ºå¯¹æŸä¸€å±‚çš„ç´¢å¼•ï¼Œé»˜è®¤ä¸ä½¿ç”¨
        **kwargs,
    ):
        super(LPIPS, self).__init__()

        self.pnet_type = net  # å­—ç¬¦ä¸²ï¼Œåˆæ­¥è®°å½•ç½‘ç»œç±»å‹
        self.pnet_tune = pnet_tune
        self.pnet_rand = pnet_rand
        self.spatial = spatial
        self.lpips = lpips
        self.version = version
        self.scaling_layer = ScalingLayer()  # ç”¨äºè¾“å…¥æ•°æ®æ ‡å‡†åŒ–çš„é¢„å¤„ç†å±‚ï¼Œå›ºå®šé¢„è®¾

        self.semantic_weight_layer = semantic_weight_layer
				
				''' é€‰æ‹©ä¸»å¹²ç½‘ç»œå¹¶åˆå§‹åŒ–'''
        if self.pnet_type in ['vgg', 'vgg16']:
            net_type = vgg16  # è¿™é‡Œçš„net_typeè¢«ä¸€ä¸ªç±»èµ‹å€¼ï¼Œç›¸å½“äºc++çš„å¼•ç”¨ï¼Œç±»å®ä¾‹åŒ–åœ¨åæ–‡ï¼Œè¿™é‡Œåªæ˜¯èµ·äº†åˆ«å
            self.chns = [64, 128, 256, 512, 512]  # æ¯ä¸€å±‚ç‰¹å¾å›¾çš„é€šé“æ•°
        elif self.pnet_type == 'alex':
            net_type = alexnet
            self.chns = [64, 192, 384, 256, 256]
        elif self.pnet_type == 'squeeze':
            net_type = squeezenet
            self.chns = [64, 128, 256, 384, 384, 512, 512]
        self.L = len(self.chns)

        self.net = net_type(pretrained=not self.pnet_rand, requires_grad=self.pnet_tune)

				'''
				æ„é€ çº¿æ€§å±‚ï¼Œçº¿æ€§å±‚çš„å·ç§¯æ ¸å¤§å°ä¸º1Ã—1ï¼Œåˆå§‹åŒ–éœ€è¦çš„å‚æ•°ä¸ºbackboneç½‘ç»œçš„å„å±‚é€šé“æ•°
				ä»¥vggç½‘ç»œä¸ºä¾‹ï¼Œè¿™äº›çº¿æ€§å±‚çš„å‚æ•°æ€»æ•°ä¸º(64 + 128 + 256 + 512 + 512) + 5 ä¸ª bias = 1472 + 5 = 1477
				'''
        if lpips:
            self.lin0 = NetLinLayer(self.chns[0], use_dropout=use_dropout)
            self.lin1 = NetLinLayer(self.chns[1], use_dropout=use_dropout)
            self.lin2 = NetLinLayer(self.chns[2], use_dropout=use_dropout)
            self.lin3 = NetLinLayer(self.chns[3], use_dropout=use_dropout)
            self.lin4 = NetLinLayer(self.chns[4], use_dropout=use_dropout)
            self.lins = [self.lin0, self.lin1, self.lin2, self.lin3, self.lin4]
            if self.pnet_type == 'squeeze':
                self.lin5 = NetLinLayer(self.chns[5], use_dropout=use_dropout)
                self.lin6 = NetLinLayer(self.chns[6], use_dropout=use_dropout)
                self.lins += [self.lin5, self.lin6]
            self.lins = nn.ModuleList(self.lins)
				
				'''æ˜¯å¦é¢„è®­ç»ƒï¼Œè°ƒç”¨è‡ªå®šä¹‰çš„é¢„è®­ç»ƒå‡½æ•°'''
            if pretrained_model_path is not None:
                load_pretrained_network(self, pretrained_model_path, False)
            elif pretrained:
                load_pretrained_network(
                    self, default_model_urls[f'{version}_{net}'], False
                )

        if eval_mode:
            self.eval()
            
```

è¦ç‚¹ï¼š

- åœ¨é€‰æ‹©ä¸»å¹²ç½‘ç»œå¹¶è®¾å®šæ¯å±‚çš„é€šé“æ•°æ—¶ï¼Œç”¨äº†ä¸€ä¸ªä¸´æ—¶çš„net_typeå˜é‡ï¼Œæ¥å—ä¸€ä¸ªç±»ï¼Œç›¸å½“äºc++çš„å¼•ç”¨ï¼Œç±»å®ä¾‹åŒ–åœ¨åæ–‡ï¼Œè¿™é‡Œåªæ˜¯èµ·äº†åˆ«åï¼›è¿™æ ·åšæ˜¯ä¸ºäº†æ–¹ä¾¿ç»Ÿä¸€ç½‘ç»œå®ä¾‹åŒ–çš„æ–¹å¼
- æœ‰æ—¶backboneç½‘ç»œæ˜¯å†»ç»“çš„ï¼Œä¸ä¼šæ›´æ–°æƒé‡ï¼Œå”¯ä¸€ä¼šå‚ä¸è®­ç»ƒçš„å‚æ•°æ˜¯è¿™äº›çº¿æ€§å±‚ï¼ˆNetLinLayerï¼‰é‡Œçš„å‚æ•°ï¼Œå³1Ã—1å·ç§¯æ ¸å¯¹æ¯ä¸ªé€šé“çš„å‚æ•°æƒé‡ï¼Œä»¥vggç½‘ç»œä¸ºä¾‹ï¼Œè¿™äº›çº¿æ€§å±‚çš„å‚æ•°æ€»æ•°ä¸º(64 + 128 + 256 + 512 + 512) + 5 ä¸ª bias = 1472 + 5 = 1477
- è°ƒç”¨ `model.eval()` ä¼šæŠŠæ¨¡å‹åˆ‡æ¢åˆ°â€œè¯„ä¼°æ¨¡å¼â€ï¼Œå…·ä½“å½±å“åŒ…æ‹¬ï¼š
    
    
    | ç»„ä»¶ | è®­ç»ƒæ¨¡å¼ï¼ˆé»˜è®¤ï¼‰ | è¯„ä¼°æ¨¡å¼ï¼ˆ`eval()`ï¼‰ |
    | --- | --- | --- |
    | Dropout | ä¼šéšæœºä¸¢å¼ƒä¸€éƒ¨åˆ†ç¥ç»å…ƒ | **ä¸ä¸¢å¼ƒï¼Œä¿æŒå…¨è¿æ¥** |
    | BatchNorm | ç”¨å½“å‰ batch çš„ç»Ÿè®¡é‡ | **ç”¨è®­ç»ƒæ—¶ä¿å­˜çš„å‡å€¼å’Œæ–¹å·®** |
    | å‚æ•°æ›´æ–° | ä¼šè¢«ä¼˜åŒ–å™¨æ›´æ–° | **ä¸ä¼šæ›´æ–°æ¢¯åº¦**ï¼ˆé€šå¸¸é…åˆ `torch.no_grad()`ï¼‰ |
    
    å‡½æ•°ä¸­`eval_mode`å¼€å…³çš„ä½œç”¨æ—¶ï¼šæˆ‘å¯èƒ½åœ¨åˆ«çš„åœ°æ–¹å·²ç»è®­ç»ƒå¥½äº†ä¸€ä¸ªLPIPSï¼Œè¦æ‹¿è¿‡æ¥ç›´æ¥è¯„åˆ†ï¼Œå°±åœ¨ `__init__()` æ—¶è¿›å…¥è¯„ä¼°æ¨¡å¼
    

```python
def forward(self, in1, in0, retPerLayer=False, normalize=True):
    '''å½’ä¸€åŒ–å¼€å…³ï¼Œä»[0,1] åˆ° [-1,1]ï¼Œå¯¹æ‰€æœ‰é€šé“å’Œæ‰€æœ‰åƒç´ ä½ç½®éƒ½æ‰§è¡Œè¿™ä¸€æ­¥'''
    if (
        normalize
    ):  
        in0 = 2 * in0 - 1
        in1 = 2 * in1 - 1

    '''å›¾åƒé¢„å¤„ç†,å¹¶åº”ç”¨backboneç½‘ç»œçš„å‰å‘ä¼ æ’­å‡½æ•°'''
    in0_input, in1_input = (
        (self.scaling_layer(in0), self.scaling_layer(in1))
        if self.version == '0.1'
        else (in0, in1)
    )
    outs0, outs1 = self.net.forward(in0_input), self.net.forward(in1_input)
    feats0, feats1, diffs = {}, {}, {}

    for kk in range(self.L):
        feats0[kk], feats1[kk] = (  # å­˜å‚¨å¤„ç†è¿‡çš„å„å±‚ç‰¹å¾å›¾
            normalize_tensor(outs0[kk]),
            normalize_tensor(outs1[kk]),
        )
        diffs[kk] = (feats0[kk] - feats1[kk]) ** 2  # è®¡ç®—ä¸¤å¼ å›¾ç‰‡å„å±‚ç‰¹å¾å›¾çš„MSE

		'''é€‰æ‹©ç”¨lpipsçº¿æ€§åŠ æƒæ¥è®¡ç®—è¯„åˆ†ï¼Œæˆ–è€…ç›´æ¥è®¡ç®—å„å±‚å¹³å‡å€¼'''
    if self.lpips:
        if self.spatial:
            res = [
                upsample(self.lins[kk](diffs[kk]), out_HW=in0.shape[2:])
                for kk in range(self.L)
            ]
        elif self.semantic_weight_layer >= 0:  # ä½¿ç”¨ç‰¹å®šå±‚çš„è¯­ä¹‰ç‰¹å¾ä½œä¸ºæƒé‡ï¼Œå¯¹å·®å¼‚åˆ†æ•°è¿›è¡ŒåŠ æƒå¹³å‡
            res = []
            semantic_feat = outs0[self.semantic_weight_layer]
            for kk in range(self.L):
                diff_score = self.lins[kk](diffs[kk])
                semantic_weight = torch.nn.functional.interpolate(
                    semantic_feat,
                    size=diff_score.shape[2:],
                    mode='bilinear',
                    align_corners=False,
                )
                avg_score = torch.sum(
                    diff_score * semantic_weight, dim=[1, 2, 3], keepdim=True
                ) / torch.sum(semantic_weight, dim=[1, 2, 3], keepdim=True)
                res.append(avg_score)
        else:  # ç›´æ¥è®¡ç®—æ¯å±‚å·®å¼‚çš„ç©ºé—´å¹³å‡å€¼
            res = [
                spatial_average(self.lins[kk](diffs[kk]), keepdim=True)
                for kk in range(self.L)
            ]
    else:
        if self.spatial:
            res = [
                upsample(diffs[kk].sum(dim=1, keepdim=True), out_HW=in0.shape[2:])
                for kk in range(self.L)
            ]
        else:
            res = [
                spatial_average(diffs[kk].sum(dim=1, keepdim=True), keepdim=True)
                for kk in range(self.L)
            ]

    val = 0
    for i in range(self.L):
        val += res[i]

		'''é»˜è®¤falseåªè¿”å›LPIPSæ€»åˆ†valï¼Œå³æ‰€æœ‰å±‚çš„å·®å¼‚åˆ†æ•°ç›¸åŠ çš„ç»“æœ'''
    if retPerLayer:
        return (val, res)
    else:
        return val.squeeze(-1).squeeze(-1)
```

è¦ç‚¹ï¼š

- ä¼ å…¥çš„in0ï¼Œin1æ˜¯å¸¸è§çš„å››ç»´tensoræ ¼å¼ï¼Œå…ˆç»è¿‡ç¼©æ”¾å†è¿›è¡Œå½’ä¸€åŒ–
- `outs0`, `outs1`ï¼šåˆ†åˆ«æ˜¯ä¸¤å¼ å›¾ç‰‡åœ¨å„å±‚çš„ç‰¹å¾å›¾åˆ—è¡¨
- å¾—åˆ°æ¯å±‚å›¾ç‰‡ä¹‹é—´çš„å·®å¼‚ä¿¡æ¯åï¼Œæˆ‘ä»¬è¦è¿›è¡Œè¯„åˆ†
- å¦‚æœå¯ç”¨ LPIPS æ¨¡å¼ï¼Œæœ‰ä¸‰ç§æƒ…å†µï¼šâ‘  æ™®é€šçº¿æ€§åŠ æƒ + ç©ºé—´å¹³å‡ â‘¡ ç©ºé—´è¾“å‡ºï¼ˆä¸å¹³å‡ï¼‰â‘¢ ä½¿ç”¨æŸä¸€å±‚è¯­ä¹‰ç‰¹å¾å›¾ä½œä¸ºæƒé‡
- å¦‚æœä¸å¯ç”¨ LPIPS æ¨¡å¼ï¼Œç›´æ¥å¹³å‡æ¯å±‚çš„ MSE

### 2.vgg16ç±»ï¼ˆå…¶ä»–ç”¨ä½œbackboneçš„CNNä¹Ÿæ˜¯åŒç†ï¼‰

```python
class vgg16(torch.nn.Module):
    def __init__(self, requires_grad=False, pretrained=True):
        super(vgg16, self).__init__()
        
        '''
        è¿™é‡Œä½¿ç”¨äº†torchvision.models.vgg16 å‡½æ•°æ¥åŠ è½½ VGG16ç½‘ç»œ
        é€šè¿‡.features æå–å‡ºVGG16ç½‘ç»œçš„å‰å‘è®¡ç®—éƒ¨åˆ†ï¼ˆå·ç§¯å±‚å’Œæ± åŒ–å±‚ï¼‰
        å†èµ‹å€¼ç»™å½“å‰çš„vggå®šåˆ¶ç½‘ç»œ
        '''
        vgg_pretrained_features = models.vgg16(weights='IMAGENET1K_V1').features
        self.slice1 = torch.nn.Sequential()
        self.slice2 = torch.nn.Sequential()
        self.slice3 = torch.nn.Sequential()
        self.slice4 = torch.nn.Sequential()
        self.slice5 = torch.nn.Sequential()
        self.N_slices = 5
        for x in range(4):
            self.slice1.add_module(str(x), vgg_pretrained_features[x])
        for x in range(4, 9):
            self.slice2.add_module(str(x), vgg_pretrained_features[x])
        for x in range(9, 16):
            self.slice3.add_module(str(x), vgg_pretrained_features[x])
        for x in range(16, 23):
            self.slice4.add_module(str(x), vgg_pretrained_features[x])
        for x in range(23, 30):
            self.slice5.add_module(str(x), vgg_pretrained_features[x])
        if not requires_grad:  # å¦‚æœä¸éœ€è¦è®¡ç®—æ¢¯åº¦ï¼Œå³è¦å†»ç»“æ¨¡å‹å‚æ•°ä¸è¿›è¡Œè°ƒæ•´ï¼Œå°†è§„åˆ™åº”ç”¨åˆ°æ¨¡å‹çš„æ‰€æœ‰å‚æ•°
            for param in self.parameters():
                param.requires_grad = False

    def forward(self, X):
    
		    '''å‰å‘ä¼ æ’­ï¼Œå¹¶ä¿å­˜æ¯ä¸ªå·ç§¯å—çš„è¾“å‡ºç»“æœ'''
        h = self.slice1(X)
        h_relu1_2 = h
        h = self.slice2(h)
        h_relu2_2 = h
        h = self.slice3(h)
        h_relu3_3 = h
        h = self.slice4(h)
        h_relu4_3 = h
        h = self.slice5(h)
        h_relu5_3 = h
        
        '''è¿”å›å‘½åå…ƒç»„'''
        vgg_outputs = namedtuple(
            'VggOutputs', ['relu1_2', 'relu2_2', 'relu3_3', 'relu4_3', 'relu5_3']
        )
        out = vgg_outputs(h_relu1_2, h_relu2_2, h_relu3_3, h_relu4_3, h_relu5_3)

        return out
```

è¦ç‚¹ï¼š

- æˆ‘ä»¬è‡ªå®šä¹‰è¿™ä¸ªvgg16ç±»çš„åŸå› æ˜¯ï¼šå®˜æ–¹çš„vgg moduleä¸ä¼šä¿å­˜æ¯ä¸€ä¸ªå·ç§¯å—çš„è¾“å‡ºç»“æœï¼Œè€Œæˆ‘ä»¬è®¡ç®—lpipséœ€è¦ä½¿ç”¨è¿™äº›ç»“æœ
- å‘½åè§„èŒƒï¼šh_relu<å·ç§¯å—åºå·>_<è¯¥å—ä¸­çš„å·ç§¯å±‚åºå·>ï¼Œå¯å‚ç…§vggæ¶æ„æ¥ç†è§£åŸæ–‡å‘½åè§„åˆ™
- `Sequential`æ˜¯PyTorchä¸­çš„ä¸€ç§å®¹å™¨ï¼Œç”¨äºå°†å¤šä¸ªç¥ç»ç½‘ç»œå±‚æŒ‰é¡ºåºç»„åˆåœ¨ä¸€èµ·ï¼Œå®ƒä»¬å°†ä¼šæŒ‰é¡ºåºæ‰§è¡Œ
- vgg_pretrained_featureså­˜å‚¨çš„æ˜¯ï¼Œvggç½‘ç»œå„å±‚çš„å·ç§¯æ ¸ï¼Œæ± åŒ–æ–¹å¼ï¼Œæ¿€æ´»å‡½æ•°ç­‰å‚æ•°ï¼Œå…·ä½“ä¸ºï¼š
    
    ```python
    Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (6): ReLU(inplace=True)
      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (8): ReLU(inplace=True)
      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (11): ReLU(inplace=True)
      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (13): ReLU(inplace=True)
      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (15): ReLU(inplace=True)
      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (18): ReLU(inplace=True)
      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (20): ReLU(inplace=True)
      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (22): ReLU(inplace=True)
      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (25): ReLU(inplace=True)
      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (27): ReLU(inplace=True)
      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (29): ReLU(inplace=True)
      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    ```
    

---

## ä¸‰ã€çŸ¥è¯†è¡¥å…¨

### 1.L1å’ŒL2

L1 å’Œ L2 æ˜¯æœ€åŸºç¡€ã€æœ€å¸¸ç”¨çš„ä¸¤ç§**æŸå¤±å‡½æ•°**ï¼Œç”¨æ¥è¡¡é‡ä¸¤ä¸ªå‘é‡æˆ–å›¾åƒä¹‹é—´çš„å·®è·ï¼Œåœ¨æ·±åº¦å­¦ä¹ ä¸­å¹¿æ³›åº”ç”¨ã€‚

L1å°±æ˜¯å·®å€¼çš„**ç»å¯¹å€¼**ä¹‹å’Œ,å³**MAE**ï¼ˆMean Absolute Error å¹³å‡ç»å¯¹è¯¯å·®ï¼‰ã€‚

$$
L1 = \sum_i|y_i-\hat y_i|

$$

L2å°±æ˜¯å·®å€¼çš„**å¹³æ–¹**ä¹‹å’Œ,å³**MSE**ï¼ˆMean Squared Error å‡æ–¹è¯¯å·®ï¼‰ã€‚

$$
L2 = \sum_i(y_i-\hat y_i)^2

$$

---

### 2.å‘½åå…ƒç»„

```python
vgg_outputs = namedtuple(
            'VggOutputs', ['relu1_2', 'relu2_2', 'relu3_3', 'relu4_3', 'relu5_3']
        )
out = vgg_outputs(h_relu1_2, h_relu2_2, h_relu3_3, h_relu4_3, h_relu5_3)
```

å…³äºvgg16ä¸­çš„è¿”å›å€¼ï¼Œä»¥å‘½åå…ƒç»„çš„æ–¹å¼è€Œä¸æ˜¯æ•°å€¼ç»„çš„æ–¹å¼è¿”å›ï¼Œä¾¿äºé€šè¿‡å­—æ®µåè®¿é—®æ¯ä¸ªç‰¹å¾å›¾ã€‚

`namedtuple` æ˜¯ Python æ ‡å‡†åº“ä¸­çš„ä¸€ä¸ªå‡½æ•°ï¼Œç”¨æ¥ç”Ÿæˆä¸€ä¸ªå…·åå…ƒç»„ç±»ã€‚å®ƒçš„ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯ç±»çš„åç§°ï¼Œé€šå¸¸é‡‡ç”¨å¤§å†™å­—æ¯è¡¨ç¤ºç±»ã€‚ä¾‹å¦‚ï¼Œ`VggOutputs` å°±æ˜¯ç±»çš„åç§°ï¼Œç”¨æ¥è¡¨ç¤ºè¿™ä¸ªå‘½åå…ƒç»„çš„ç±»å‹ã€‚
è¿™ä¸ªå‘½åå…ƒç»„å°±åƒå¼±åŒ–çš„å­—å…¸ï¼Œåœ¨åˆ›å»ºæ—¶ï¼Œé¡ºåºç¡®å®škeyå€¼ï¼Œåœ¨åˆå§‹åŒ–æ—¶ï¼ŒæŒ‰é¡ºåºå°†keyå€¼ä¸æœ‰æ„ä¹‰çš„æ•°å€¼è¿æ¥åœ¨ä¸€èµ·ï¼Œè¿™æ ·æˆ‘ä»¬å°±å¯ä»¥é€šè¿‡`out.relu1_2`è®¿é—®ç¬¬ä¸€å±‚è¾“å‡ºï¼Œè€Œä¸æ˜¯`out[0]`ï¼Œå¯è¯»æ€§æ˜æ˜¾æå‡